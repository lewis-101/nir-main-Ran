{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# 用于连接jupyter notebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'G:\\\\Image_Decomposition\\\\nir-main-Ran'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(r'G:\\Image_Decomposition\\nir-main-Ran')\n",
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "import model\n",
    "from model import Siren, Homography\n",
    "from util import get_mgrid, apply_homography, jacobian, VideoFitting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def train(path, total_steps, lambda_interf=0.001, lambda_excl=0.002, verbose=True, steps_til_summary=100):\n",
    "    transform = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize(torch.Tensor([0.5, 0.5, 0.5]), torch.Tensor([0.5, 0.5, 0.5]))\n",
    "    ])\n",
    "    v = VideoFitting(path, transform)\n",
    "    videoloader = DataLoader(v, batch_size=1, pin_memory=True, num_workers=0)\n",
    "\n",
    "    g = Homography(hidden_features=256, hidden_layers=2)\n",
    "    g.cuda()\n",
    "    f1 = Siren(in_features=2, out_features=3, hidden_features=256,\n",
    "               hidden_layers=4, outermost_linear=True)\n",
    "    f1.cuda()\n",
    "    f2 = Siren(in_features=3, out_features=3, hidden_features=128,\n",
    "               hidden_layers=4, outermost_linear=True)\n",
    "    f2.cuda()\n",
    "\n",
    "    params = chain(g.parameters(), f1.parameters(), f2.parameters())\n",
    "    optim = torch.optim.Adam(lr=1e-4, params=params)\n",
    "\n",
    "    model_input, ground_truth = next(iter(videoloader))\n",
    "    model_input, ground_truth = model_input[0].cuda(), ground_truth[0].cuda()\n",
    "\n",
    "    batch_size = (v.H * v.W) // 4\n",
    "    for step in range(total_steps):\n",
    "        start = (step * batch_size) % len(model_input)\n",
    "        end = min(start + batch_size, len(model_input))\n",
    "\n",
    "        xy = model_input[start:end, :-1].requires_grad_()\n",
    "        t = model_input[start:end, [-1]].requires_grad_()\n",
    "        h = g(t)\n",
    "        xy_ = apply_homography(xy, h)\n",
    "        o_scene = f1(xy_)\n",
    "        o_moire = f2(torch.cat((xy, t), -1))\n",
    "        o = o_scene + o_moire\n",
    "        loss_recon = ((o - ground_truth[start:end]) ** 2).mean()\n",
    "        loss_interf = o_moire.abs().mean()\n",
    "\n",
    "        g_scene = jacobian(o_scene, xy_)\n",
    "        g_moire = jacobian(o_moire, xy)\n",
    "        n_scene = (g_moire.norm(dim=0, keepdim=True) / g_scene.norm(dim=0, keepdim=True)).sqrt()\n",
    "        n_moire = (g_scene.norm(dim=0, keepdim=True) / g_moire.norm(dim=0, keepdim=True)).sqrt()\n",
    "        loss_excl = (torch.tanh(n_scene * g_scene) * torch.tanh(n_moire * g_moire)).pow(2).mean()\n",
    "\n",
    "        loss = loss_recon + lambda_interf * loss_interf + lambda_excl * loss_excl\n",
    "\n",
    "        if verbose and not step % steps_til_summary:\n",
    "            print(\"Step [%04d/%04d]: recon=%0.4f, interf=%0.4f, excl=%0.4f\" % (step, total_steps, loss_recon, loss_interf, loss_excl))\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    return g, f1, f2, v.video"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0000/3000]: recon=0.1368, interf=0.0422, excl=0.0023\n",
      "Step [0100/3000]: recon=0.0041, interf=0.1384, excl=0.2167\n",
      "Step [0200/3000]: recon=0.0026, interf=0.1351, excl=0.1935\n",
      "Step [0300/3000]: recon=0.0020, interf=0.1319, excl=0.1832\n",
      "Step [0400/3000]: recon=0.0016, interf=0.1306, excl=0.1779\n",
      "Step [0500/3000]: recon=0.0015, interf=0.1296, excl=0.1748\n",
      "Step [0600/3000]: recon=0.0011, interf=0.1294, excl=0.1696\n",
      "Step [0700/3000]: recon=0.0012, interf=0.1298, excl=0.1632\n",
      "Step [0800/3000]: recon=0.0008, interf=0.1307, excl=0.1569\n",
      "Step [0900/3000]: recon=0.0006, interf=0.1312, excl=0.1508\n",
      "Step [1000/3000]: recon=0.0007, interf=0.1316, excl=0.1502\n",
      "Step [1100/3000]: recon=0.0005, interf=0.1321, excl=0.1448\n",
      "Step [1200/3000]: recon=0.0005, interf=0.1324, excl=0.1435\n",
      "Step [1300/3000]: recon=0.0004, interf=0.1326, excl=0.1393\n",
      "Step [1400/3000]: recon=0.0006, interf=0.1327, excl=0.1399\n",
      "Step [1500/3000]: recon=0.0005, interf=0.1329, excl=0.1361\n",
      "Step [1600/3000]: recon=0.0005, interf=0.1327, excl=0.1348\n"
     ]
    }
   ],
   "source": [
    "# g, f1, f2, orig = train('./data/moire', 3000)\n",
    "# g, f1, f2, orig = train('./data/ranbow', 3000)\n",
    "g, f1, f2, orig = train('./data/ranbow_1', 3000)\n",
    "# g, f1, f2, orig = train('./data/ranbow_2', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    N, _, H, W = orig.size()\n",
    "    xyt = get_mgrid([H, W, N]).cuda()\n",
    "    h = g(xyt[:, [-1]])\n",
    "    o_scene = f1(apply_homography(xyt[:, :-1], h))\n",
    "    o_moire = f2(xyt)\n",
    "    o_scene = o_scene.view(H, W, N, 3).permute(2, 0, 1, 3).cpu().detach().numpy()\n",
    "    o_moire = o_moire.view(H, W, N, 3).permute(2, 0, 1, 3).cpu().detach().numpy()\n",
    "    o_scene = (np.clip(o_scene * 0.5 + 0.5, 0, 1) * 255).astype(np.uint8)\n",
    "    o_moire = (np.clip(o_moire * 0.5 + 0.5, 0, 1) * 255).astype(np.uint8)\n",
    "    o_scene = [o_scene[i] for i in range(len(o_scene))]\n",
    "    o_moire = [o_moire[i] for i in range(len(o_moire))]\n",
    "    orig = orig.permute(0, 2, 3, 1).detach().numpy()\n",
    "    orig = ((orig * 0.5 + 0.5) * 255).astype(np.uint8)\n",
    "    orig = [orig[i] for i in range(len(orig))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Save out video\n",
    "# ! pip install --user imageio imageio-ffmpeg\n",
    "import imageio\n",
    "fn_orig = os.path.join('./data/moire_orig_1.mp4')\n",
    "fn_scene = os.path.join('./data/moire_scene_1.mp4')\n",
    "fn_moire = os.path.join('./data/moire_interf_1.mp4')\n",
    "imageio.mimwrite(fn_orig, orig, fps=1)\n",
    "imageio.mimwrite(fn_scene, o_scene, fps=1)\n",
    "imageio.mimwrite(fn_moire, o_moire, fps=1)\n",
    "\n",
    "# Display video inline\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "data_url_orig = \"data:video/mp4;base64,\" + b64encode(open(fn_orig, 'rb').read()).decode()\n",
    "data_url_scene = \"data:video/mp4;base64,\" + b64encode(open(fn_scene, 'rb').read()).decode()\n",
    "data_url_moire = \"data:video/mp4;base64,\" + b64encode(open(fn_moire, 'rb').read()).decode()\n",
    "HTML(f'''\n",
    "<video width=512 controls autoplay loop>\n",
    "      <source src=\"{data_url_orig}\" type=\"video/mp4\">\n",
    "</video>\n",
    "<video width=512 controls autoplay loop>\n",
    "      <source src=\"{data_url_scene}\" type=\"video/mp4\">\n",
    "</video>\n",
    "<video width=512 controls autoplay loop>\n",
    "      <source src=\"{data_url_moire}\" type=\"video/mp4\">\n",
    "</video>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "name": "explore_siren.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "conda-env-pytorch_gpu-py",
   "language": "python",
   "display_name": "Python [conda env:pytorch_gpu] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}